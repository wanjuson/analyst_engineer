{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제5장. 머신러닝 프로세스\n",
    "## 제3절. 성능평가기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) MSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "msle = mean_squared_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수식을 함수로 만들기\n",
    "import numpy as np\n",
    "def MAPE(y_test, y_pred):\n",
    "    mape = np.mean(np.abs((y_test - y_pred)/y_test)) * 100\n",
    "    return mape\n",
    "mape = MAPE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 분류분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도는 (TN + TP) / (TN + FP + FN + TP)\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 혼동행렬\n",
    "# TN : 예측값을 Negative(0)로 예측했고 실제값도 Negative(0)\n",
    "# FP : 예측값을 Positive(1)로 예측했지만 실제값은 Negative(0)\n",
    "# FN : 예측값을 Negative(0)로 예측했지만 실제 값은 Positive(1)\n",
    "# TP : 예측값을 Positive(1)로 예측했고 실제 값도 Positive(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 정밀도와 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정밀도\n",
    "# 정의 : Positive로 예측한 것들 중 실제로도 Positive인 것들의 비율\n",
    "# 특징 \n",
    "# a. Positive 예측성능을 더욱 정밀하게 측정하기 위한 평가지표\n",
    "# b. 양성 예측도라 불림\n",
    "# c. 정밀도가 상대적인 중요성을 가지는 경우 : 실제 Negative인 데이터를 Positive로 잘못 예측 했을때 업무상 큰 영향이 발생할 때\n",
    "# 수식 : TP / (FP + TP)\n",
    "\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 재현율\n",
    "# 정의 : 실제 Positive인 것들 중 Positive로 예측한 것들의 비율\n",
    "# 특징 \n",
    "# a. 민감도 또는 TPR이라고 불림\n",
    "# b. 재현율이 상대적인 중요성을 가지는 경우 : 실제 Positive인 데이터를 Negative로 잘못 예측\n",
    "# 수식 : TP / (FN + TP)\n",
    "\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) F1 스코어\n",
    "# 정의 : 실제 Positive인 것들 중 Positive로 예측한 것들의 비율\n",
    "# 특징 : 정밀도와 재현율이 어느 한쪽으로 치우치치 않고 적절한 조화를 이룰 때 상대적으로 높은 수치를 나타냄\n",
    "# 수식 : F1 = 2*(percision * recall) / (percision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) ROC 곡선과 AUC 스코어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC 곡선\n",
    "# 정의 : FPR이 변할 때 TPR이 변하는 것을 나타내는 곡선 (ROC)\n",
    "# TPR을 Y축으로 FPR을 X축으로 하는 그래프\n",
    "# 분류 결정 임계값을 조절하면서 FPR이 0부터 1까지 별할 때 TPR의 변화값을 그래프로 나타냄\n",
    "# 우상향 그래프로 그려짐\n",
    "\n",
    "# 사이킷런 API 호출\n",
    "from sklearn.metrics import roc_curve\n",
    "# FPR, TPR, 임곗값 할당하기\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred, pos_label = 1)\n",
    "# ROC 곡선 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUC 스코어\n",
    "## 정의\n",
    "# a. Area Under the ROC roc_curve\n",
    "# b. Roc 곡선 아래의 면적\n",
    "# c. 1에 가까울수록 예측성능이 우수하다고 판단\n",
    "\n",
    "## 특징\n",
    "# AUC 값이 커디려면 FPR이 작을때 TPR 값이 커야함\n",
    "# 우상향 직선에서 멀어지도 왼쪽 상단의 모서리 쪽으로 가파르게 곡선이 이동할수록 AUC가 1에 가까워짐\n",
    "# 랜덤 수준의 auc값은 0.5\n",
    "\n",
    "\n",
    "# 사이킷런 API\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# FPR, TPR, 임곗값 할당하기\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred, pos_label = 1)\n",
    "# AUC 값\n",
    "auc = auc(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
