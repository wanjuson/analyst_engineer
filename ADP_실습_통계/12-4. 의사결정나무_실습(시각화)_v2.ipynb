{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사결정나무 (시각화)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://graphviz.org/download/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install graphviz\n",
    "# !pip install pydot\n",
    "# !pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from IPython.display import Image\n",
    "import pydot\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[예제 2.]__   \n",
    "iris 데이터의 Species를 분류하는 의사결정나무 분석을 실시하고 오분류표를 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4) (105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋, 평가셋 분리하기\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, stratify=y, train_size=0.7\n",
    "                                                                    , test_size=0.3, random_state=123)\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사결정나무 모델 실행\n",
    "iris_clf = DecisionTreeClassifier(max_depth=5)\n",
    "iris_clf = iris_clf.fit(train_x, train_y)\n",
    "iris_prediction = iris_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22808\\3687711709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdt_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_dot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\신주현\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             self.__setattr__(\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m             )\n\u001b[0;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\신주현\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "# 의사결정나무 시각화\n",
    "\n",
    "# 시각화 라이브러리에 삽입해야하는 변수 생성하기\n",
    "# 원본 데이터의 변수이름을 추출하고, 타겟변수 이름을 0, 1로 설정\n",
    "feature_names = feature_columns\n",
    "target_name = np.array(['0', '1', '2'])\n",
    "#print(target_name) #결과 ['0', '1', '2']\n",
    "\n",
    "# Graphviz로 의사결정나무 시각화하기\n",
    "dt_dot_data = tree.export_graphviz(iris_clf, feature_names=feature_names, class_names=target_name, \n",
    "                            filled=True, max_depth= 5)\n",
    "dt_graph = pydotplus.graph_from_dot_data(dt_dot_data)\n",
    "\n",
    "Image(dt_graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.86      0.80      0.83        15\n",
      "           2       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.89      0.89      0.89        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 리포트 생성하기\n",
    "class_report_iris = classification_report(test_y, iris_prediction)\n",
    "print(class_report_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 2, 0, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 2, 1, 1, 2,\n",
       "       1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 2, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 2, 2, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 2,\n",
       "       1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_clf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_auc_score in module sklearn.metrics._ranking:\n",
      "\n",
      "roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)\n",
      "    Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
      "    from prediction scores.\n",
      "    \n",
      "    Note: this implementation can be used with binary, multiclass and\n",
      "    multilabel classification, but some restrictions apply (see Parameters).\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "        True labels or binary label indicators. The binary and multiclass cases\n",
      "        expect labels with shape (n_samples,) while the multilabel case expects\n",
      "        binary label indicators with shape (n_samples, n_classes).\n",
      "    \n",
      "    y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "        Target scores.\n",
      "    \n",
      "        * In the binary case, it corresponds to an array of shape\n",
      "          `(n_samples,)`. Both probability estimates and non-thresholded\n",
      "          decision values can be provided. The probability estimates correspond\n",
      "          to the **probability of the class with the greater label**,\n",
      "          i.e. `estimator.classes_[1]` and thus\n",
      "          `estimator.predict_proba(X, y)[:, 1]`. The decision values\n",
      "          corresponds to the output of `estimator.decision_function(X, y)`.\n",
      "          See more information in the :ref:`User guide <roc_auc_binary>`;\n",
      "        * In the multiclass case, it corresponds to an array of shape\n",
      "          `(n_samples, n_classes)` of probability estimates provided by the\n",
      "          `predict_proba` method. The probability estimates **must**\n",
      "          sum to 1 across the possible classes. In addition, the order of the\n",
      "          class scores must correspond to the order of ``labels``,\n",
      "          if provided, or else to the numerical or lexicographical order of\n",
      "          the labels in ``y_true``. See more information in the\n",
      "          :ref:`User guide <roc_auc_multiclass>`;\n",
      "        * In the multilabel case, it corresponds to an array of shape\n",
      "          `(n_samples, n_classes)`. Probability estimates are provided by the\n",
      "          `predict_proba` method and the non-thresholded decision values by\n",
      "          the `decision_function` method. The probability estimates correspond\n",
      "          to the **probability of the class with the greater label for each\n",
      "          output** of the classifier. See more information in the\n",
      "          :ref:`User guide <roc_auc_multilabel>`.\n",
      "    \n",
      "    average : {'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'\n",
      "        If ``None``, the scores for each class are returned. Otherwise,\n",
      "        this determines the type of averaging performed on the data:\n",
      "        Note: multiclass ROC AUC currently only handles the 'macro' and\n",
      "        'weighted' averages.\n",
      "    \n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by considering each element of the label\n",
      "            indicator matrix as a label.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average, weighted\n",
      "            by support (the number of true instances for each label).\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average.\n",
      "    \n",
      "        Will be ignored when ``y_true`` is binary.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    max_fpr : float > 0 and <= 1, default=None\n",
      "        If not ``None``, the standardized partial AUC [2]_ over the range\n",
      "        [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n",
      "        should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n",
      "        computation currently is not supported for multiclass.\n",
      "    \n",
      "    multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\n",
      "        Only used for multiclass targets. Determines the type of configuration\n",
      "        to use. The default value raises an error, so either\n",
      "        ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n",
      "    \n",
      "        ``'ovr'``:\n",
      "            Stands for One-vs-rest. Computes the AUC of each class\n",
      "            against the rest [3]_ [4]_. This\n",
      "            treats the multiclass case in the same way as the multilabel case.\n",
      "            Sensitive to class imbalance even when ``average == 'macro'``,\n",
      "            because class imbalance affects the composition of each of the\n",
      "            'rest' groupings.\n",
      "        ``'ovo'``:\n",
      "            Stands for One-vs-one. Computes the average AUC of all\n",
      "            possible pairwise combinations of classes [5]_.\n",
      "            Insensitive to class imbalance when\n",
      "            ``average == 'macro'``.\n",
      "    \n",
      "    labels : array-like of shape (n_classes,), default=None\n",
      "        Only used for multiclass targets. List of labels that index the\n",
      "        classes in ``y_score``. If ``None``, the numerical or lexicographical\n",
      "        order of the labels in ``y_true`` is used.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    auc : float\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n",
      "            <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n",
      "    \n",
      "    .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n",
      "           probability estimation trees (Section 6.2), CeDER Working Paper\n",
      "           #IS-00-04, Stern School of Business, New York University.\n",
      "    \n",
      "    .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n",
      "            Recognition Letters, 27(8), 861-874.\n",
      "            <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n",
      "    \n",
      "    .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n",
      "            Under the ROC Curve for Multiple Class Classification Problems.\n",
      "            Machine Learning, 45(2), 171-186.\n",
      "            <http://link.springer.com/article/10.1023/A:1010920819831>`_\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    average_precision_score : Area under the precision-recall curve.\n",
      "    roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n",
      "        (ROC) curve given an estimator and some data.\n",
      "    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n",
      "        (ROC) curve given the true and predicted values.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Binary case:\n",
      "    \n",
      "    >>> from sklearn.datasets import load_breast_cancer\n",
      "    >>> from sklearn.linear_model import LogisticRegression\n",
      "    >>> from sklearn.metrics import roc_auc_score\n",
      "    >>> X, y = load_breast_cancer(return_X_y=True)\n",
      "    >>> clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
      "    >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
      "    0.99...\n",
      "    >>> roc_auc_score(y, clf.decision_function(X))\n",
      "    0.99...\n",
      "    \n",
      "    Multiclass case:\n",
      "    \n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> X, y = load_iris(return_X_y=True)\n",
      "    >>> clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
      "    >>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n",
      "    0.99...\n",
      "    \n",
      "    Multilabel case:\n",
      "    \n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.datasets import make_multilabel_classification\n",
      "    >>> from sklearn.multioutput import MultiOutputClassifier\n",
      "    >>> X, y = make_multilabel_classification(random_state=0)\n",
      "    >>> clf = MultiOutputClassifier(clf).fit(X, y)\n",
      "    >>> # get a list of n_output containing probability arrays of shape\n",
      "    >>> # (n_samples, n_classes)\n",
      "    >>> y_pred = clf.predict_proba(X)\n",
      "    >>> # extract the positive columns for each output\n",
      "    >>> y_pred = np.transpose([pred[:, 1] for pred in y_pred])\n",
      "    >>> roc_auc_score(y, y_pred, average=None)\n",
      "    array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])\n",
      "    >>> from sklearn.linear_model import RidgeClassifierCV\n",
      "    >>> clf = RidgeClassifierCV().fit(X, y)\n",
      "    >>> roc_auc_score(y, clf.decision_function(X), average=None)\n",
      "    array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, iris_clf.predict_proba(test_x), multi_class='ovr') # multi_class는 multi_class='ovr' 옵션 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": "12.4",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5aa634c14859627405404137fecabd2d911e45a844039ce454abb52cf9f696dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
