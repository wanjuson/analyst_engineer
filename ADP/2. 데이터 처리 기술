2장. 데이터 처리 기술
분산 파일 시스템
[구글 파일 시스템]
1. 가정
 - 저가형 서버로 구성된 환경으로 서버의 고장이 빈번하게 발생할 수 있다.
 - 대부분의 파일은 대용량이다.
 - 작업 부하는 주로 연속적으로 많은 데이터를 읽는 연산이거나 임의의 영역에서 적은 데이터를 읽는 연산이다.
 - 파일에 대한 연산은 주로 순차적으로 데이터를 추가하며 파일에 대한 갱신은 드물게 이루어진다.
 - 여러 클라이언트에서 동시에 동일한 파일에 데이터를 추가하는 환경에서 동기화 오버헤드를 최소화할 수 있는 방법이 요구된다.
 - 낮은 응답 지연시간보다 높은 처리율이 중요하다.

2. Master Node
 - 전체를 관리하고 통제항는 중앙 서버
 - 단일 마스터 구조 : 모든 메타데이터를 메모리상에서 관리
 - 주기적으로 하트비트 메시지를 이용하여 chunk 서버에 저장된 chunk들의 상태를 체크해 상태에 따라 chunk를 재복제하거나 재분산하는 것과 같은 회복 동작 수행
 
3. Chunk Server
 - 물리적인 서버. 실제 입출력을 처리
 - 고정된 크기의 chunk들로 나누어 chunk server에 분산/저장된다.
 - 클라이언트는 파일에 접근하기 위하여 마스터로부터 해당 파일의 chunk가 저장된 chunk 서버의 위치와 핸들을 받아온다.
 - 로컬 디스크에 chunk를 저장/관리하면서 클라이언트로부터의 chunk 입출력 요청을 처리한다.
 - chunk는 마스터에 의해 생성/삭제될 수 있으며 식별자에 의해 구별된다.
 
4. Client
 - 파일 입출력을 요청하는 클라이언트 어플리케이션
 - POSIX 지원 X. 파일 시스템 인터페이스와 유사한 자체 인터페이스를 지원한다.
 
[하둡 파일 시스템]
 - 블록구조(Chunk Based) : 기본적으로 3개의 블록 복제본을 저장한다.
 - 마스터-슬레이브 아키텍처 : 하나의 네임노드와 다수의 데이터노드
 
1. 네임노드
 - 메타데이터 관리 : 네임노드는 클라이언트에게 빠르게 응답할 수 있도록 메도리에 전체 메타데이터를 로딩해서 관리한다.
 - 데이터노드 모니터링 : 데이터노드는 3초마다 네임노드에게 하드비트 메시지를 전송한다.
  (하드비트 : 데이터노드 상태 정보와 데이터노드에 저장돼 있는 블록의 목록으로 구성)
 - 블록관리 : 장애가 발생한 데이터노드를 발견하면 해당 데이터노드의 블록을 새로운 데이터노드로 복제한다.
 - 클라이언트 요청 접수
 
2. 데이터노드
 - 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지한다,.
 - 클라이언트의 데이터 입출력 요청 처리
 - HDFS에서 파일을 한번 쓰이면 변경되지 않는다고 가정한다.
  따라서 HDFS는 데이터에 대한 스트리밍 접근을 요청하면 배치 작업에 적합한 응용을 대상으로 한다.
  
[러스터]
 - 클러스터 파일 시스템에서 개발한 객제 기반 클러스터 파일 시스템
 
1. 구성
 1) 클라이언트 파일 시스템
  - 리눅스, VFS에서 설치할 수 있는 파일 시스템
  - 메타데이터 서버와 객체 저장 서버들과 통신하면서 클라이언트 응용에 파일 시스템 인터페이스를 제공한다.
 2) 메타데이터 서버 : 파일 시스템의 이름 공간과 파일에 대한 메타데이터를 관리한다.
 3) 객체 저장 서브들
  - 파일 데이터를 저장하고 클라이언트로부터 객체 입출력 요청을 처리한다.
  - 객체는 객체 저장 서버들에 스트라이핑되어 분산/저장한다.
  
 2. 특징
  - 리눅스에서 사용
  - POSIX가 호환되는 유닉스 파일 시스템 인터페이스 제공
  - 동시 접근이 적을 때는 클라이언트 캐시를 이용한 라이트백 캐시 사용하고 동시 접근이 많으면 클라이언트 캐시를 사용함으로써 발생할 수 있는 오버헤드를 감소시킨다.
  - 클라이언트에서 메타데이터 변경에 대한 갱신 코드를 생성하고 나중에 메타데이터 서버에 전달한다.
  - 파일 메타데이터와 파일 데이터에 대한 동시성 제어를 위해 별도의 잠금을 사용한다.
  
 ㅁ 데이터베이스 클러스터
  - DB를 여러개의 서버가 나눠서 처리하도록 클러스터링
 1. 장점
  - 고가용성 : 장애가 발생하더라도 서비스가 중단되지 않음
  - 병렬처리 : 바른 데이터 검색 및 처리 성능
  - 성능향상
 
 2. 공유디스크 VS 무공유
  1)공유디스트
  - 높은 고장 감내성
  - 클러스터가 커지면 디스크 영역에서 병목현상 발생
  - 모든 노드가 데이터를 수정할 수없기에 노드간의 동기화 작업을 위한 별도의 커뮤니케이션 채널이 필요하다.
  - Oracle RAC
  2)무공유
  - 노드 확장에 제한이 없다.
  - 노드에 장애가 발생할 경우를 대비해 고장 감내성을 구성해야 한다.
  - IBC DB@ ICE
  
3. Oracle RAC 데이터베이스 서버
 - 애플리케이션 파티션과 데이터 파티션이 동시에 구현
 - 클러스터의 모든 노드에서 실행되며 데이터는 공유 스토리지에 저장
 - 클러스터 내의 모든 노드는 데이터베이스의 모든 데이블에 동등하게 엑세스하며 특정 노드가 데이터를 소유하는 개념은 없다.
  따라서 데이터를 파티셔닝할 필요는 없지만 성능 향상을 위해 빈번하게 파티셔닝 된다.
  - 가용성, 확장성, 비용절감
  
 4. 마이크로소프트 SQL 서버
  - 연합 데이터베이스 형태
  - 네트워크를 이용해 연결
  - 무공유 / 수평적 분할
  - DPV뷰 : 테이블을 논리적으로 분리해 물리적으로 분산된 각 노드에 생성하고 각 노듸의 데이터베이스 인스턴스 사이에 링크를 구성한 후 모든 파티션에 대해 UNION ALL을 이용해
   논리적인 뷰를 구성하는 방식으로 분산된 환경의 데이터에 대한 싱글 뷰를 제공
  - 파티셔닝 정책에 맞게 테이블과 뷰를 생성해야 하고 전역 스키마 정보가 없기 때문에 질의 수행을 위해 모든 노드를 액세스 해야 한다.
  
  
  
